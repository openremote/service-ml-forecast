name: service-ml-forecast

services:
  service-ml-forecast:
    build:
      context: ..
      dockerfile: docker/Dockerfile
      args:
        ML_OR_URL: ${ML_OR_URL} # OpenRemote URL
        ML_OR_KEYCLOAK_URL: ${ML_OR_KEYCLOAK_URL} # OpenRemote Keycloak URL
        ML_SERVICE_URL: ${ML_SERVICE_URL} # Url to reach the back-end service, should be the same as ML_API_ROOT_PATH
        ML_WEB_ROOT_PATH: ${ML_WEB_ROOT_PATH} # Public path for the front-end (e.g. when behind a reverse proxy)
    container_name: service-ml-forecast
    ports:
      - "8000:8000"
    environment:
      - ML_LOG_LEVEL=${ML_LOG_LEVEL} # Log level to use
      - ML_ENVIRONMENT=${ML_ENVIRONMENT} # Environment to run the service in
      - ML_API_ROOT_PATH=${ML_API_ROOT_PATH} # Public path for the back-end (e.g. when behind a reverse proxy)
      - ML_OR_URL=${ML_OR_URL} # OpenRemote URL
      - ML_OR_KEYCLOAK_URL=${ML_OR_KEYCLOAK_URL} # OpenRemote Keycloak URL
      - ML_OR_SERVICE_USER=${ML_OR_SERVICE_USER} # OpenRemote service user
      - ML_OR_SERVICE_USER_SECRET=${ML_OR_SERVICE_USER_SECRET} # OpenRemote service user secret
    volumes:
      # Model storage
      - ../deployment/data/models:/app/deployment/data/models
      # Config storage
      - ../deployment/data/configs:/app/deployment/data/configs
    restart: unless-stopped
    networks:
      - ml-network
    extra_hosts:
      - "host.docker.internal:host-gateway"

networks:
  ml-network:
    driver: bridge
